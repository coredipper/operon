\section{Reference Implementation}

To validate the framework's feasibility, we provide a reference implementation in Python.
The implementation, \texttt{operon-ai}\footnote{\url{https://github.com/coredipper/operon}}, is described in this section,
which summarizes key components and demonstrates that the biological motifs translate into practical code.

\subsection{Architecture Overview}

The implementation follows the biological organization:

\begin{itemize}[leftmargin=*]
\item \textbf{Core Types} (\texttt{core/types.py}): Signal, ActionProtein, FoldedProtein, CellState---the
categorical objects with their biological semantics.
\item \textbf{Surveillance} (\texttt{surveillance/}): The immune system implementation with MHCDisplay,
TCell, Thymus, and ImmuneMemory components.
\item \textbf{Healing} (\texttt{healing/}): ChaperoneLoop implementing the structural self-healing pattern.
\item \textbf{Quality} (\texttt{quality/}): Chaperone protein with multi-strategy folding.
\item \textbf{Topology} (\texttt{topology/}): Network motifs including Quorum, Cascade, and Oscillator.
\end{itemize}

\subsection{Immune System Implementation}

The Adaptive Immunity motif is implemented as an integrated surveillance system:

\begin{verbatim}
@dataclass
class ImmuneSystem:
    thymus: Thymus          # Negative selection
    treg: RegulatoryTCell   # Tolerance/suppression
    memory: ImmuneMemory    # Threat signatures
    displays: dict[str, MHCDisplay]
    tcells: dict[str, TCell]
\end{verbatim}

The \texttt{MHCPeptide} class captures behavioral fingerprints---statistical signatures of agent output
including response time distributions, vocabulary hashes, confidence patterns, and error rates. This
directly implements the MHC presentation concept from Section 4.4.

\paragraph{Two-Signal Activation.}
T-cell activation requires both signals:
\begin{verbatim}
class Signal1(Enum):
    SELF = "self"        # Matches baseline
    NON_SELF = "non_self"  # Anomalous behavior

class Signal2(Enum):
    NONE = "none"
    CANARY_FAILED = "canary"
    CROSS_VALIDATED = "cross"
    REPEATED_ANOMALY = "repeat"
\end{verbatim}

An agent is only flagged when \texttt{Signal1 == NON\_SELF} \textbf{and} \texttt{Signal2 != NONE}.
This prevents false positives from transient anomalies, implementing the immunological requirement
for costimulation.

\subsection{Chaperone Implementation}

The Chaperone implements multi-strategy folding with provenance tracking:

\begin{verbatim}
class FoldingStrategy(Enum):
    STRICT = "strict"       # Exact JSON match
    EXTRACTION = "extraction"  # Find JSON in text
    LENIENT = "lenient"     # Type coercion
    REPAIR = "repair"       # Fix malformed JSON
\end{verbatim}

The \texttt{ChaperoneLoop} extends this into a healing loop where validation errors are fed back
to the generator:

\begin{verbatim}
class ChaperoneLoop:
    def heal(self, prompt: str) -> HealingResult:
        for attempt in range(self.max_retries + 1):
            raw = self.generator(prompt, error_context)
            folded = self.chaperone.fold_enhanced(raw, schema)
            if folded.valid:
                return HealingResult(HEALED, folded)
            error_context = self._format_error(folded)
        return HealingResult(DEGRADED, ubiquitin_tagged=True)
\end{verbatim}

This directly implements the GroEL/GroES cage metaphor: the error trace becomes input to the
repair process, enabling context-aware correction.

\subsection{Trust and Provenance}

The implementation uses a simplified 3-level trust hierarchy that collapses the theoretical 4-level
model $\{U, T, S, R\}$ for practical deployment:

\begin{verbatim}
class IntegrityLabel(IntEnum):
    UNTRUSTED = 0   # User input, Retrieved, Self-generated
    VALIDATED = 1   # Schema-checked (Chaperone-folded)
    TRUSTED = 2     # Tool-grounded (deterministic output)
\end{verbatim}

This simplification merges \texttt{User}, \texttt{Retrieved}, and \texttt{Self} into \texttt{UNTRUSTED},
reflecting the common case where all non-tool sources require validation before trust elevation. The
full 4-level model can be recovered by subclassing \texttt{IntegrityLabel} with additional levels when
finer-grained provenance tracking is required.

The \texttt{ApprovalToken} provides proof-carrying authorization for privileged operations:

\begin{verbatim}
@dataclass(frozen=True)
class ApprovalToken:
    request_hash: str
    issuer: str
    integrity: IntegrityLabel
    timestamp: datetime
\end{verbatim}

This implements the Trust-Gated Lens: actions requiring high integrity must present a valid
ApprovalToken with sufficient integrity level.

\subsection{Evaluation Protocol (Synthetic Harness)}

We define a synthetic evaluation harness to exercise three motifs with reproducible procedures:
\begin{enumerate}[leftmargin=*]
\item \textbf{Chaperone Folding.} Generate JSON schemas with 3--8 required fields. Sample valid JSON and
apply 1--3 corruptions (e.g., missing quotes, trailing commas, type swaps, dropped fields). Measure the
fraction of outputs that can be folded into the schema under STRICT versus cascaded strategies
(EXTRACTION $\to$ LENIENT $\to$ REPAIR).
\item \textbf{Immune Detection.} Simulate agents with baseline distributions over response time,
vocabulary hash, structure hash, and confidence. Train on baseline samples, then introduce
``compromised'' agents by shifting distribution parameters and injecting anomalous hashes.
Measure sensitivity and false positive rate under the two-signal activation rule.
\item \textbf{Healing Loop.} Generate malformed outputs and run the ChaperoneLoop with and without
error-context feedback. Measure recovery within $k$ attempts (default $k=3$).
\end{enumerate}

\paragraph{Implementation.}
The harness is implemented in \texttt{eval/} with a JSON-configured CLI:
\begin{verbatim}
python -m eval.run --suite all --config eval/configs/default.json \
  --out eval/results/latest.json
\end{verbatim}
The output is a machine-readable JSON report (per-suite config + metrics) suitable for direct inclusion
in tables or plots.

\paragraph{Status.}
Synthetic runs indicate consistent qualitative gains (cascade $>$ strict, error-context $>$ blind retry,
immune detection $>$ chance). Table~\ref{tab:eval-summary} reports aggregated numeric results across
multiple seeds; real-world validation with LLM outputs remains ongoing.

\paragraph{Aggregated Results.}
We ran the harness across 100 deterministic seeds (1--100) using the default harness config
(\path{eval/configs/default.json}). The
aggregate results (pooled across seeds with Wilson 95\% intervals; $N$ is total pooled trials) are reported
in Table~\ref{tab:eval-summary}.

\paragraph{External Benchmark Suites.}
In addition to the synthetic suites above, the harness includes
suites derived from external benchmarks: (1)~function-call schemas from
the Berkeley Function Calling Leaderboard (BFCL)~\cite{patil2023gorilla}
test the Chaperone's folding pipeline against realistic tool-use schemas,
and (2)~prompt injection attack templates from
AgentDojo~\cite{debenedetti2024agentdojo} generate adversarial behavioral
shifts to test Immune System detection. These suites use the same
deterministic corruption and simulation methodology; results appear in the
lower section of Table~\ref{tab:eval-summary}.

\input{../eval/results/summary.tex}

\subsection{Limitations}

The current implementation has several limitations:

\begin{itemize}[leftmargin=*]
\item \textbf{Epiplexity:} Not yet implemented. The operational approximation (Equation 18)
requires embedding infrastructure not included in the current release.
\item \textbf{Multi-cellular coordination:} Morphogen gradients are specified but the
orchestrator implementation is incomplete.
\item \textbf{Benchmarking:} Synthetic harness is implemented, but real-world validation with LLM outputs
and adversarial inputs is still in progress.
\end{itemize}

We release the implementation to enable community validation and extension of the framework.
